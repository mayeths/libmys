#!/usr/bin/env python3
VERSION="2023.09.15"

import sys
import argparse
import shutil
import pathlib
import tempfile
import functools
import base64
import hashlib
from collections import OrderedDict
from typing import Union, List

class DefaultConfig:
    def __init__(self):
        self.nodelist = "cn[001-008]"
        self.sockets_per_node = 2
        self.numas_per_socket = 2
        self.cores_per_numa = 8

class YanchengConfig(DefaultConfig):
    def __init__(self):
        super().__init__()
        self.nodelist = "bn[001-400]"
        self.sockets_per_node = 2
        self.numas_per_socket = 1
        self.cores_per_numa = 64
        #
        self.key = "YC"
        self.desc = "Yancheng AMD EPYC 7H12"

class Kunpeng920Config(DefaultConfig):
    def __init__(self):
        super().__init__()
        self.nodelist = "kunpeng-node[101-108]"
        self.sockets_per_node = 2
        self.numas_per_socket = 2
        self.cores_per_numa = 32
        #
        self.key = "KP"
        self.desc = "Kunpeng ARM 6426"

CONFIGS = [YanchengConfig(), Kunpeng920Config()]

QUIET = False
def eprint(text, end='\n', force=False):
    global QUIET
    if force or not QUIET:
        print(text, end=end, file=sys.stderr)

def eexit(code, text=None, end='\n'):
    if text is not None:
        eprint('[ERROR] ' + text, end=end, force=True)
    sys.exit(code)


class HardwareInfo:
    sockets_per_node: int
    numas_per_node: int
    numas_per_socket: int
    cores_per_node: int
    cores_per_socket: int
    cores_per_numa: int


    def __init__(self, sockets_per_node: int, numas_per_socket: int, cores_per_numa: int):
        self.sockets_per_node = sockets_per_node

        self.numas_per_socket = numas_per_socket
        self.numas_per_node = self.numas_per_socket * self.sockets_per_node

        self.cores_per_numa = cores_per_numa
        self.cores_per_socket = self.cores_per_numa * self.numas_per_socket
        self.cores_per_node = self.cores_per_numa * self.numas_per_node


@functools.total_ordering
class Slot:
    node_index: int
    region_index: int # in node
    start: int # in node
    stop: int # in node

    def __init__(self, node_index: int, region_index: int, slot_start: int, slot_stop: int) -> None:
        self.node_index = node_index
        self.region_index = region_index
        self.start = slot_start
        self.stop = slot_stop

    def __eq__(self, other) -> bool:
        if not isinstance(other, Slot):
            return False
        return ((self.node_index, self.region_index, self.start, self.stop) ==
                (other.node_index, self.region_index, other.start, other.stop))

    def __lt__(self, other) -> bool:
        if not isinstance(other, Slot):
            return False
        return ((self.node_index, self.region_index, self.start, self.stop) <
                (other.node_index, self.region_index, other.start, other.stop))


class Rank:
    id: int
    node: Union[str, None]
    slots: Union[list[int], None]

    def __init__(self, id, node=None, slots=None):
        self.id = id
        self.node = node
        self.slots = slots

    def __str__(self):
        if self.node is None:
            raise ValueError(f"rank {self.id} is not assigned to any node")
        if not self.slots:
            raise ValueError(f"rank {self.id} is not assigned to any core range on {self.node}")
        self.slots.sort()
        if len(self.slots) == 1:
            slot_str = f"{self.slots[0]}"
        elif Rank._is_sorted_index_continuous(self.slots):
            slot_str = f"{self.slots[0]}-{self.slots[-1]}"
        else:
            slot_str = f",".join(self.slots)
        return f"rank {self.id}={self.node} slot={slot_str}"

    @staticmethod
    def _is_sorted_index_continuous(arr: list[int]):
        for i in range(1, len(arr)):
            if arr[i] - arr[i - 1] > 1:
                return False
        return True


# Fingerprint is only correct for contiguous slot mapping
def print_fingerprint(hwinfo: HardwareInfo, ranks: list[Rank], region: str,
                      target_node: str, symbols=["+", "-"], void_symbol=".", devide_on_region=True):
    if region == "numa":
        cores_per_region = hwinfo.cores_per_numa
    elif region == "socket":
        cores_per_region = hwinfo.cores_per_socket
    elif region == "node":
        cores_per_region = hwinfo.cores_per_node

    ranks = [rank for rank in ranks if rank.node == target_node]
    if not ranks:
        return
    core_to_ranks = [-1] * hwinfo.cores_per_node
    for i in range(len(ranks)):
        rank = ranks[i]
        for core in rank.slots:
            core_to_ranks[core] = i

    result = f"{ranks[0].node} |"
    symbol_index = 0
    last_rank = 0
    for i in range(hwinfo.cores_per_node):
        if devide_on_region and i != 0 and i % cores_per_region == 0:
            result += "|"
        elif not devide_on_region and i != 0 and i % hwinfo.cores_per_numa == 0:
            result += "|"
        rank = core_to_ranks[i]
        if rank == -1:
            result += void_symbol
        elif rank != last_rank:
            symbol_index = (symbol_index + 1) % len(symbols)
            result += symbols[symbol_index]
            last_rank = rank
        else:
            result += symbols[symbol_index]
    result += "|"
    eprint(result)


def _expand_range(text: str) -> List[str]:
    ranges = text.split(",")
    result = []
    for rang in ranges:
        pivots: List[str] = rang.split("-")
        if len(pivots) > 2:
            eexit(1, f'Invalid node list range: "{rang}"')

        if len(pivots) == 1:
            if pivots[0].isdigit():
                result.append(pivots[0])
            else:
                eexit(1, f'Invalid node list range: "{rang}"')
            continue

        digits = len(pivots[0])

        if pivots[0].isdigit():
            left = int(pivots[0])
        else:
            eexit(1, f'Invalid node list range: "{rang}"')

        if pivots[1].isdigit():
            if len(pivots[1]) != len(pivots[0]): # e.g., 99-100 is invalid becuase we expect 099-100
                eexit(1, f'Invalid node list range: "{rang}"')
            right = int(pivots[1])
        else:
            if len(pivots[1]) != 0:
                eexit(1, f'Invalid node list range: "{rang}"')
            right = left # '04-' is valid (we follow slurm to interpret it as 04)

        arr = [i for i in range(left, right+1)]
        if len(arr) == 0: # e.g., left = 5 right = 4
            eexit(1, f'Invalid node list range: "{rang}"')
        for i in arr:
            result.append(f"{i:0{digits}d}")

    return list(OrderedDict.fromkeys(result))

# bn004,bn9[0-1][7,8,9],cn[01-02]0
#           ^^^  ^^^^^     ^^^^^   ranges
# ^^^^^ ^^^^^^^^^^^^^^^ ^^^^^^^^^^ labels
# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ nodelist
def expand_nodelist(nodelist: str) -> List[str]:
    labels = []
    state = 0
    left_label = 0
    for i in range(len(nodelist)):
        if nodelist[i] == ",":
            if state == 0:
                right_label = i - 1
                label = nodelist[left_label : right_label + 1]
                labels.append(label)
                left_label = i + 1
        elif nodelist[i] == "[":
            if state == 0:
                state = 1
            else:
                eexit(1, f'Invalid node list: "{nodelist}"')
        elif nodelist[i] == "]":
            if state == 1:
                state = 0
            else:
                eexit(1, f'Invalid node list: "{nodelist}"')

    labels.append(nodelist[left_label : len(nodelist)])
    labels = [label for label in labels if len(label) != 0]

    if len(labels) == 0:
        eexit(1, f'Invalid node list: "{nodelist}"')

    result = []

    for label in labels:
        state = 0
        left_range = 0
        ranges = []
        for i in range(len(label)):
            if label[i] == "[":
                if state == 0:
                    left_range = i
                    state = 1
                else:
                    eexit(1, f'Invalid range in node list: "{label}"')
            elif label[i] == "]":
                if state == 1:
                    ranges.append((left_range, i))
                    state = 0
                else:
                    eexit(1, f'Invalid range in node list: "{label}"')
        if len(ranges) == 0:
            result.append(label)
            continue
        spans = []
        last_pos = 0
        for left_range, right_range in ranges:
            spans.append([label[last_pos : left_range]])
            spans.append(_expand_range(label[left_range + 1 : right_range]))
            last_pos = right_range + 1
        if len(spans) == 0:
            eexit(1, f'Invalid range in node list: "{label}"')
        if last_pos != len(label):
            spans.append(label[last_pos:])
        expanding = spans[0]
        for span in spans[1:]:
            gen = []
            for a in expanding:
                for b in span:
                    gen.append(a + b)
            expanding = gen
        result += expanding

    return result


def fill_ranks(hwinfo: HardwareInfo, nodes: List[str], region: str,
               left_most_cores: bool, enable_imbalance: bool,
               num_node: int, num_rank: int, threads_per_rank: int):
    if region == "numa":
        regions_per_node = hwinfo.numas_per_node
        cores_per_region = hwinfo.cores_per_numa
    elif region == "socket":
        regions_per_node = hwinfo.sockets_per_node
        cores_per_region = hwinfo.cores_per_socket
    elif region == "node":
        regions_per_node = 1
        cores_per_region = hwinfo.cores_per_node

    num_region = regions_per_node * num_node
    ranks_per_region = num_rank // (regions_per_node * num_node)
    ranks_per_node = ranks_per_region * regions_per_node
    ranks_tail = num_rank - ranks_per_node * num_node
    imbalanced = ranks_tail > 0

    slots_per_region = ranks_per_region * threads_per_rank
    slots_per_node = slots_per_region * regions_per_node

    # Check if requested slot is too many for node. We first assert node-wise for clear
    max_num_node = len(nodes)
    if num_node > max_num_node:
        eexit(1, f"Requested {num_node} nodes but "+
                 f"node list contains {max_num_node} nodes only.")

    num_slots = num_rank * threads_per_rank
    max_slot = num_node * hwinfo.cores_per_node
    # Check if requested slot is too many for region.
    if num_slots > max_slot:
        eexit(1, f'Requested {num_slots} cores but up to '
                +f'{max_slot} cores are allocatable on node list.')

    if imbalanced and not enable_imbalance:
        if num_rank % (num_node * hwinfo.sockets_per_node) == 0:
            eexit(1, f'Cannot split {num_rank} ranks to {num_region} {region}s on {num_node} nodes equally. '
                    +f'Try "--align=socket" or insist with "--imbalance".')
        elif num_rank % num_node == 0:
            eexit(1, f'Cannot split {num_rank} ranks to {num_region} {region}s on {num_node} nodes equally. '
                    +f'Try "--align=node" or insist with "--imbalance".')
        else:
            eexit(1, f'Cannot split {num_rank} ranks to {num_region} {region}s on {num_node} nodes equally. '
                    +f'Insist with "--imbalance".')

    slots: List[Slot] = []

    for i in range(num_rank):
        # Distribute by user specified nodes first. For example, user specified 2 node and 2 ranks,
        # We should put each rank on different node
        node_index = i % num_node # global
        region_index = (i % num_region) // num_node # in node
        region_index_g = node_index * regions_per_node + region_index # global
        inner_index = i // num_region # in region
        if left_most_cores:
            slot_start = region_index * cores_per_region + inner_index * threads_per_rank
            slot_stop = slot_start + threads_per_rank - 1
        else:
            slot_stop = (region_index + 1) * cores_per_region - 1 - inner_index * threads_per_rank
            slot_start = slot_stop - threads_per_rank + 1
        slot = Slot(node_index, region_index, slot_start, slot_stop)
        slots.append(slot)

    slots.sort()
    ranks = []
    used_nodes = set()

    for i in range(num_rank):
        slot = slots[i]
        node_name = nodes[slot.node_index]
        used_nodes.add(node_name)
        core_list = [i for i in range(slot.start, slot.stop+1)]
        rank = Rank(i, node_name, core_list)
        region_ok = slot.region_index >= 0 and slot.region_index < regions_per_node
        core_list_b1 = slot.region_index * cores_per_region
        core_list_b2 = (slot.region_index + 1) * cores_per_region - 1
        core_list_ok = slot.start >= core_list_b1 and slot.stop <= core_list_b2
        if not region_ok or not core_list_ok:
            eexit(1, f'rank {i} on {node_name} violate {region} {slot.region_index} boundary: ' +
                     f'[{slot.start}, {slot.stop}] not in [{core_list_b1}, {core_list_b2}]. ' +
                     f'Try "--align=node" or other configuration.')

        ranks.append(rank)

    return ranks, imbalanced


def base64_encode(text: str):
    return base64.urlsafe_b64encode(text.encode()).decode().replace("=", "")

def base64_decode(sanitized_text: str):
    padded_text = sanitized_text + '=' * (-len(sanitized_text) % 4)
    return base64.urlsafe_b64decode(padded_text.encode()).decode()

def sha256_encode(text: str):
    return hashlib.sha256(text.encode()).hexdigest()

def sha512_encode(text: str):
    return hashlib.sha512(text.encode()).hexdigest()


class StoreAction(argparse._StoreAction):
    def __call__(self, parser, namespace, values, option_string=None):
        super(StoreAction, self).__call__(parser, namespace, values, option_string)
        setattr(namespace, self.dest+'_provided', True)

class StoreConstAction(argparse._StoreConstAction):
    def __call__(self, parser, namespace, values, option_string=None):
        super(StoreConstAction, self).__call__(parser, namespace, values, option_string)
        setattr(namespace, self.dest+'_provided', True)

class HelpAction(argparse._HelpAction):
    def __call__(self, parser, namespace, values, option_string=None):
        super(HelpAction, self).__call__(parser, namespace, values, option_string)
        setattr(namespace, self.dest+'_provided', True)

class VersionAction(argparse._VersionAction):
    def __call__(self, parser, namespace, values, option_string=None):
        super(VersionAction, self).__call__(parser, namespace, values, option_string)
        setattr(namespace, self.dest+'_provided', True)

def provided(namespace: argparse.Namespace, option: str):
    return True if getattr(namespace, f"{option}_provided", None) else False

class UsageAction(argparse.Action):
    def __init__(self, option_strings, dest=argparse.SUPPRESS, default=argparse.SUPPRESS, **kwargs):
        super(UsageAction, self).__init__(option_strings, dest, nargs=0, default=default, **kwargs)

    def __call__(self, parser, namespace, values, option_string=None):
        print('----------------------------')
        print("1. Using rankgen inside a sbatch's submit script")
        print("   After slurm allocates resources for your job, it run the script on the machine you ran sbatch.")
        print('   Some SLURM_* variables are set for your script, where SLURM_NODELIST can be passed to rankgen.')
        print('   The following example is example.sbatch.sh')
        print('')
        print("   #!/bin/bash")
        print("   #SBATCH -J example")
        print("   #SBATCH -N 1")
        print("   #SBATCH -n 4")
        print("   #SBATCH --cpus-per-task 2")
        print("   #SBATCH --exclusive")
        print("   rankfile=$(rankgen -t -q -w $SLURM_NODELIST 1 4 2)")
        print("   mpirun -np 4 -rf $rankfile ./a.out")
        print('----------------------------')
        print('2. Using rankgen with salloc on the fly')
        print('   After slurm allocates resources for your job, it run the command on the machine you ran salloc.')
        print('   Some SLURM_* variables such as SLURM_NODELIST are also set for the environment of command.')
        print('')
        print('   export N=1 P=4 T=2')
        print('   export rankgen_cmd="\$(rankgen -t -q -w \$SLURM_NODELIST $N $P $T)"')
        print('   salloc --exclusive -N $N bash -c "mpirun -np $P -rf $rankgen_cmd ./a.out"')
        print('----------------------------')
        print('3. Using rankgen with salloc for a group of fixed nodes')
        print('   You may ask slurm for fixed nodes to ensure stable and reproducible performance.')
        print('')
        print('   export N=100 P=400 T=2')
        print('   export rankfile=./${N}-${P}-${T}.rf')
        print('   rankgen -q -w cn[101-200] -o $rankfile $N $P $T')
        print('   salloc --exclusive -N $N -w cn[101-200] mpirun -np $P -rf $rankfile ./a.out')
        print('----------------------------')
        print('x. Using rankgen with srun')
        print("   This is impossible because srun invoke mpirun internally and we can't pass the rankfile to it.")
        print("   rankgen aims to fine-grained process placement with OpenMPI mpirun.")
        print("   Use the high-level options srun supports instead. See https://slurm.schedmd.com/mc_support.html")
        print('----------------------------')
        parser.exit()

def main():
    global QUIET
    terminal_width = shutil.get_terminal_size((80, 20))[0]
    parser = argparse.ArgumentParser(
        prog='rankgen',
        usage='%(prog)s [OPTIONS] <num_node> <num_rank> <threads_per_rank>',
        description=f'OpenMPI rankfile genrator for easy fine-grained process placement (version {VERSION})\n',
        add_help=False,
        epilog='Example: %(prog)s --finger=all -w "bn000,cn2[0-1][1,0],dn999" --imbalance --align=socket 5 7 3',
        formatter_class=lambda prog: argparse.ArgumentDefaultsHelpFormatter(prog, max_help_position=terminal_width)
    )
    parser.add_argument('num_node', type=int, help=f"Number of nodes to use")
    parser.add_argument('num_rank', type=int, help=f"Number of ranks")
    parser.add_argument('threads_per_rank', type=int, default=1, help=f"Number of threads per rank")
    # metavar='' for removing dest variable from help text

    cfg = DefaultConfig()

    hargs = parser.add_argument_group('hardware information arguments')
    for v in CONFIGS:
        flag = f"-{v.key}"
        help = f'{v.desc} [-w "{v.nodelist}" -S {v.sockets_per_node} -N {v.numas_per_socket} -C {v.cores_per_numa}]'
        hargs.add_argument(flag, dest=v.key, action=StoreConstAction, const=True, default=False, help=help, metavar='')
    hargs.add_argument('-S', '--sockets-per-node', action=StoreAction, dest='sockets_per_node', default=cfg.sockets_per_node, type=int, help=f"Sockets per node", metavar='')
    hargs.add_argument('-N', '--numas-per-socket', action=StoreAction, dest='numas_per_socket', default=cfg.numas_per_socket, type=int, help=f"Numas per socket", metavar='')
    hargs.add_argument('-C', '--cores-per-numa', action=StoreAction, dest='cores_per_numa', default=cfg.cores_per_numa, type=int, help=f"Cores per numa", metavar='') # TODO: Support hwthread
    # cat /sys/devices/system/cpu/cpu0/topology/thread_siblings_list for hwthread list
    gargs = parser.add_argument_group('generator arguments')
    gargs.add_argument('-o', dest='outfile', action=StoreAction, default="<stdout>", type=str, help=f"Output to file", metavar='')
    gargs.add_argument('-t', dest='use_tempfile', action=StoreConstAction, const=True, default=False, help="Output to tempfile and print its path to <stdout>", metavar='')
    gargs.add_argument('-w', '--nodelist', dest='nodelist', action=StoreAction, default=cfg.nodelist, type=str, help="The list of nodes in SLURM's nodelist syntax", metavar='')
    gargs.add_argument('-a', '--align', dest='region', action=StoreAction, default='numa', choices=['numa', 'socket', 'node'], help="Align ranks to the numa/socket/node region", metavar='')
    gargs.add_argument('-l', '--left', dest='left_most_cores', action=StoreConstAction, const=True, default=False, help="Use left-most slots in the region", metavar='')
    gargs.add_argument('-i', '--imbalance', dest='imbalance', action=StoreConstAction, const=True, default=False, help="Allow imbalancing over regions", metavar='')
    gargs.add_argument('-f', '--finger', dest='fingerprint', action=StoreAction, default="first", choices=['first', 'all', 'no'], help="Display first/all/no fingerprint of node", metavar='')
    # Please note that modify name of tempfile bellow every time add critical arugments influencing the result of generator, for example hwthread
    parser.add_argument('-q', '--quiet', dest='quiet', action=StoreConstAction, const=True, default=False, help="Don't print summary to <stderr>", metavar='')
    parser.add_argument('-u', '--usage', action=UsageAction, help="Show extended usages and exit", metavar='')
    parser.add_argument('-v', '--version', action=VersionAction, version=f'{VERSION}', help="Show version number and exit")
    parser.add_argument('-h', '--help', action=HelpAction, help=f"Show this help message and exit")

    # Try to parse arguments
    try:
        args = parser.parse_args()
    except SystemExit as e:
        if e.code != 0:
            eprint(' ' * len(parser.prog) + f'  run "{parser.prog} -h" for more information')
        exit(e.code)

    # Required arguments
    num_node = args.num_node
    num_rank = args.num_rank
    threads_per_rank = args.threads_per_rank
    # Check predef options
    for predef in CONFIGS:
        if provided(args, predef.key):
            cfg = predef
            break
    # Machine Config
    modified_config = False
    if provided(args, f"nodelist"):
        cfg.nodelist = args.nodelist
        modified_config = True
    if provided(args, f"sockets_per_node"):
        cfg.sockets_per_node = args.sockets_per_node
        modified_config = True
    if provided(args, f"numas_per_socket"):
        cfg.numas_per_socket = args.numas_per_socket
        modified_config = True
    if provided(args, f"cores_per_numa"):
        cfg.cores_per_numa = args.cores_per_numa
        modified_config = True
    hwinfo = HardwareInfo(cfg.sockets_per_node, cfg.numas_per_socket, cfg.cores_per_numa)
    # Optional arguments
    outfile = args.outfile
    use_tempfile = args.use_tempfile
    left_most_cores = args.left_most_cores
    region = args.region
    imbalance = args.imbalance
    fingerprint = args.fingerprint
    QUIET = args.quiet

    if num_node <= 0:
        eexit(1, f"Invalid number of node: {num_node}")
    if num_rank <= 0:
        eexit(1, f"Invalid number of rank: {num_rank}")
    if threads_per_rank <= 0:
        eexit(1, f"Invalid threads per rank: {threads_per_rank}")
    if cfg.sockets_per_node <= 0:
        eexit(1, f"Invalid sockets per node: {cfg.sockets_per_node}")
    if cfg.numas_per_socket <= 0:
        eexit(1, f"Invalid numas per socket: {cfg.numas_per_socket}")
    if cfg.cores_per_numa <= 0:
        eexit(1, f"Invalid cores per numa: {cfg.cores_per_numa}")

    nodes = expand_nodelist(cfg.nodelist)
    ranks, imbalanced = fill_ranks(hwinfo, nodes, region, left_most_cores, imbalance, num_node, num_rank, threads_per_rank)

    eprint(f"{parser.prog}: {parser.description}")
    eprint(f"\x1b[1;32m=== Platform Summary\x1b[0m")
    if getattr(cfg, "desc", None):
        if modified_config:
            eprint(f"Based on platform config: [{cfg.key}] {cfg.desc}")
        else:
            eprint(f"Used platform config without modification: [{cfg.key}] {cfg.desc}")
    eprint(f"Node list: {cfg.nodelist} (total {len(nodes)} nodes)")
    eprint(f"Sockets per node: {hwinfo.sockets_per_node}")
    eprint(f"Numas per socket: {hwinfo.numas_per_socket} (total {hwinfo.numas_per_node} numas per node)")
    eprint(f"Cores per numa: {hwinfo.cores_per_numa} (total {hwinfo.cores_per_node} cores per node)")
    eprint(f"")
    eprint(f"\x1b[1;32m=== Generator Summary\x1b[0m")
    eprint(f"Number of node: {num_node}")
    eprint(f"Number of rank: {num_rank}")
    eprint(f"Number of thread: {threads_per_rank} (per rank)")
    eprint(f"* Total [{num_rank * threads_per_rank}] slots are required among [{num_node}] nodes.")
    eprint(f"* Align to the [{'left' if left_most_cores else 'right'}] boundary of [{region}].")
    eprint(f"* Ranks are [{'imbalanced' if imbalanced else 'balanced'}] in their distributed among [{region}]s.")
    eprint(f"")

    content = "\n".join([str(rank) for rank in ranks])
    if use_tempfile:
        # Prevent collision of number with '-', for example 1125 can be treat as 1-12-5 or 11-2-5
        sign1 = f'{cfg.sockets_per_node}-{cfg.numas_per_socket}-{cfg.cores_per_numa}'
        sign2 = f'{num_node}-{num_rank}-{threads_per_rank}-{region}-{"L" if left_most_cores else "R"}-{"I" if imbalance else "B"}'
        sign3 = cfg.nodelist
        bign1 = base64_encode(sign1) # bign1 = sign1
        bign2 = base64_encode(sign2) # bign2 = sign2
        hashed = base64_encode(sign3)
        if len(hashed) < 250:
            bign3 = f"B/{hashed}"
        else:
            bign3 = f"S/{sha256_encode(sign3)}"
        dir = tempfile.gettempdir()
        file = f"{dir}/{bign1}/{bign2}/{bign3}.rf"
        path = pathlib.Path(file)
        do_write = True
        if path.exists():
            with open(file) as tmp:
                old_content = tmp.read()
            if old_content == content:
                do_write = False
        if do_write:
            path.parent.mkdir(parents=True, exist_ok=True)
            with open(file, "w") as tmp:
                tmp.write(content)
        eprint(f"\x1b[1;32m=== Temporary file used to write output:\x1b[0m")
        print(tmp.name)
    elif outfile == "<stdout>":
        eprint(f"\x1b[1;32m=== Content generated to <stdout>:\x1b[0m")
        print(content)
        eprint(f"")
    else:
        pathlib.Path(outfile).parent.mkdir(parents=True, exist_ok=True)
        try:
            with open(outfile, "w") as f:
                f.write(content)
        except:
            eprint(f"Cannot open {outfile} to write output.")
    if fingerprint == "first":
        eprint(f"\x1b[1;32m=== Fingerprint of first node\x1b[0m")
        print_fingerprint(hwinfo, ranks, region, nodes[0])
    elif fingerprint == "all":
        eprint(f"\x1b[1;32m=== Fingerprint of all {num_node} nodes\x1b[0m")
        for i in range(num_node):
            print_fingerprint(hwinfo, ranks, region, nodes[i])

if __name__ == '__main__':
    main()
